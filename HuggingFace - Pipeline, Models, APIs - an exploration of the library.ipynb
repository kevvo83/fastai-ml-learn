{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNMfPnG54q2Bi5qS8Xr5qUy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# HuggingFace - Pipeline, Models, APIs - an exploration of the library and what it does"],"metadata":{"id":"gVkmS5xJK6yG"}},{"cell_type":"markdown","source":["## Introduction\n","\n","This purpose of this notebook is to explore a bit more in depth into:\n","\n","1. HF's `pipeline` and `HuggingFacePipeline`\n","  * What do these objects do\n","  * When to use one or the other\n","2. HF Model load\n","  * Does this load model artifacts from the HF API server?\n","  * What is the impact of a model not fitting into serverless API"],"metadata":{"id":"KAOhJ7i3LA-G"}},{"cell_type":"markdown","source":["## References\n","\n","1. Accompanying notebook: [HuggingFace - Naive RAG and LLM Judge.ipynb](https://colab.research.google.com/drive/1iZpEjLO_6JS6F8oWSuwYJ2UiBppXN8p8?usp=sharing)\n","2. HF documentation:\n","  * [NLP Learn](https://huggingface.co/learn/nlp-course/chapter1/1?fw=pt)\n","  * [Pipelines](https://huggingface.co/docs/transformers/en/main_classes/pipelines)"],"metadata":{"id":"V6iR5ow2LaUe"}},{"cell_type":"markdown","source":["## TODOs\n","\n","* Model cache?"],"metadata":{"id":"P7Z_kh0MRE4e"}},{"cell_type":"markdown","source":["## Prep"],"metadata":{"id":"DdjgXx1Pjq8D"}},{"cell_type":"markdown","source":["### Install dependencies"],"metadata":{"id":"rgT5jpJejttU"}},{"cell_type":"code","source":["!pip install torch transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QbWS2UZPjsD7","executionInfo":{"status":"ok","timestamp":1717644118186,"user_tz":-600,"elapsed":107711,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}},"outputId":"8977c779-8f98-44fa-f42c-3f5e720c8dd1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"vajBr_4Ij1wY"}},{"cell_type":"code","source":["import torch\n","from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification"],"metadata":{"id":"AP3dcLg1j2dR","executionInfo":{"status":"ok","timestamp":1717644141513,"user_tz":-600,"elapsed":21154,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Breakdown of pipeline\n","\n","`Pipeline` consists of:\n","1. `Tokenizer` object\n","2. `Model` object\n","3. Post Processing object\n","\n"],"metadata":{"id":"hhzy6FJojM-P"}},{"cell_type":"markdown","source":["### Build/use a pipeline by calling `Tokenizer` and `Model` separately\n","\n","Reference: https://huggingface.co/learn/nlp-course/chapter2/6?fw=pt"],"metadata":{"id":"iYo_eIgvjeUy"}},{"cell_type":"code","source":["!export HF_HOME=/.hf_cache"],"metadata":{"id":"7TttTORgks6Q","executionInfo":{"status":"ok","timestamp":1717644253979,"user_tz":-600,"elapsed":441,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Model card: https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english\n","# Model type: text-classification\n","model_checkpoint = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n","\n","sequences = [\n","    \"I've been waiting for a HuggingFace course my whole life.\",\n","    \"So have I!\"\n","]\n","\n","inputs = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\") # pt return_tensor = torch.Tensor return type - also supports tf and np\n","\n","assert isinstance(inputs['input_ids'], torch.Tensor)\n","assert 'input_ids' in list(inputs.keys())\n","assert 'attention_mask' in list(inputs.keys())\n","\n","inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2puVwF1jb9y","executionInfo":{"status":"ok","timestamp":1717644585551,"user_tz":-600,"elapsed":1225,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}},"outputId":"c97c8dbe-b905-4af2-a215-3c1b3518c684"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n","          2607,  2026,  2878,  2166,  1012,   102],\n","        [  101,  2061,  2031,  1045,   999,   102,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["inputs['input_ids'].numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGw-QP0nmn6X","executionInfo":{"status":"ok","timestamp":1717644785533,"user_tz":-600,"elapsed":3,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}},"outputId":"7f9567ea-f8d3-4b59-eab2-637e8b9483d3"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,\n","        12172,  2607,  2026,  2878,  2166,  1012,   102],\n","       [  101,  2061,  2031,  1045,   999,   102,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0]])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["print(tokenizer.decode(inputs['input_ids'][0])) # what the tokens look like\n","print(tokenizer.decode(inputs['input_ids'][1])) # what the tokens look like\n","\n","print(tokenizer.pad_token_id)\n","print(tokenizer.pad_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1ySLzWFlQ94","executionInfo":{"status":"ok","timestamp":1717644948981,"user_tz":-600,"elapsed":3,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}},"outputId":"787a26c8-f89d-4e4f-ec1e-60113cd56a0c"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] i've been waiting for a huggingface course my whole life. [SEP]\n","[CLS] so have i! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","0\n","[PAD]\n"]}]},{"cell_type":"code","source":["output = model(**inputs)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skvqq1XnnQMh","executionInfo":{"status":"ok","timestamp":1717644896635,"user_tz":-600,"elapsed":1728,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}},"outputId":"4d3518a6-6d1c-4fc2-95ae-a71b7a45b7a1"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n","        [-3.6183,  3.9137]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["### Model output Logits to Classification\n","\n","Logit is the model output prior to activation?"],"metadata":{"id":"tkk1dm07pQeK"}},{"cell_type":"code","source":["torch.sigmoid(output.logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hz91R7do5cY","executionInfo":{"status":"ok","timestamp":1717645477133,"user_tz":-600,"elapsed":6,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}},"outputId":"02668b42-d680-465f-8c49-676266943c82"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.1735, 0.8337],\n","        [0.0261, 0.9804]], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["mask_of_probabilities = torch.sigmoid(output.logits).squeeze(dim=0) > 0.5\n","\n","torch.nn.Softmax(dim=1)(output.logits) # softmax on the logits returned by the model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QAGf3LGvp9c6","executionInfo":{"status":"ok","timestamp":1717645960695,"user_tz":-600,"elapsed":5,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}},"outputId":"92836d09-07ca-4983-e7a7-6b3fcb3b532f"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[4.0195e-02, 9.5980e-01],\n","        [5.3534e-04, 9.9946e-01]], grad_fn=<SoftmaxBackward0>)"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["model.config.label2id # the softmax of the model output logits shows that the index of the highest probability result = 1 - which indicates POSITIVE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MvU91HFjo1Bs","executionInfo":{"status":"ok","timestamp":1717645314846,"user_tz":-600,"elapsed":345,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}},"outputId":"07121029-2eff-40f2-98f4-3165ad1a4d18"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'NEGATIVE': 0, 'POSITIVE': 1}"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["## Pipeline object"],"metadata":{"id":"1biZGACHntIs"}},{"cell_type":"code","source":["sentiment_classification_pipeline = pipeline(\n","    model=model,\n","    tokenizer=tokenizer,\n","    task=\"sentiment-analysis\",\n","    # temperature=0.2,\n","    # do_sample=True,\n","    # repetition_penalty=1.1,\n","    # return_full_text=True,\n","    # max_new_tokens=400,\n",")\n","\n","sentiment_classification_pipeline(sequences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_28QfTVnvVM","executionInfo":{"status":"ok","timestamp":1717645152485,"user_tz":-600,"elapsed":1049,"user":{"displayName":"Kevin Lawrence","userId":"03979172887082762896"}},"outputId":"49005ef4-9983-438a-94a8-fd4a0e7c2edf"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n"," {'label': 'POSITIVE', 'score': 0.9994646906852722}]"]},"metadata":{},"execution_count":36}]}]}